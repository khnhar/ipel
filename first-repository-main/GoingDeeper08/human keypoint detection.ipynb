{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95c19c53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf  # 'as tf'를 추가하여 TensorFlow를 'tf'로 사용할 수 있게 함\n",
    "\n",
    "# Tensorflow가 활용할 GPU가 장착되어 있는지 확인합니다.\n",
    "tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568137ca",
   "metadata": {},
   "source": [
    "##데이터 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62f9b7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 주의! ray를 tensorflow보다 먼저 import하면 오류가 발생할 수 있습니다\n",
    "import io, json, os, math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Add, Concatenate, Lambda\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, MaxPool2D\n",
    "from tensorflow.keras.layers import UpSampling2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import ray\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PROJECT_PATH = os.getenv('HOME') + '/aiffel/aiffel_quest'\n",
    "IMAGE_PATH = os.path.join(PROJECT_PATH, 'images')\n",
    "MODEL_PATH = os.path.join(PROJECT_PATH, 'models')\n",
    "MODEL_SIMPLEBASELINE_PATH = os.path.join(PROJECT_PATH, 'simplebaseline')\n",
    "TFRECORD_PATH = os.path.join(PROJECT_PATH, 'tfrecords_mpii')\n",
    "TRAIN_JSON = os.path.join(PROJECT_PATH, 'mpii_human_pose_v1_u12_2', 'train.json')\n",
    "VALID_JSON = os.path.join(PROJECT_PATH, 'mpii_human_pose_v1_u12_2', 'validation.json')\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d350db8",
   "metadata": {},
   "source": [
    "json 파싱하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bd6e0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"joints_vis\": [\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"joints\": [\n",
      "    [\n",
      "      620.0,\n",
      "      394.0\n",
      "    ],\n",
      "    [\n",
      "      616.0,\n",
      "      269.0\n",
      "    ],\n",
      "    [\n",
      "      573.0,\n",
      "      185.0\n",
      "    ],\n",
      "    [\n",
      "      647.0,\n",
      "      188.0\n",
      "    ],\n",
      "    [\n",
      "      661.0,\n",
      "      221.0\n",
      "    ],\n",
      "    [\n",
      "      656.0,\n",
      "      231.0\n",
      "    ],\n",
      "    [\n",
      "      610.0,\n",
      "      187.0\n",
      "    ],\n",
      "    [\n",
      "      647.0,\n",
      "      176.0\n",
      "    ],\n",
      "    [\n",
      "      637.0201,\n",
      "      189.8183\n",
      "    ],\n",
      "    [\n",
      "      695.9799,\n",
      "      108.1817\n",
      "    ],\n",
      "    [\n",
      "      606.0,\n",
      "      217.0\n",
      "    ],\n",
      "    [\n",
      "      553.0,\n",
      "      161.0\n",
      "    ],\n",
      "    [\n",
      "      601.0,\n",
      "      167.0\n",
      "    ],\n",
      "    [\n",
      "      692.0,\n",
      "      185.0\n",
      "    ],\n",
      "    [\n",
      "      693.0,\n",
      "      240.0\n",
      "    ],\n",
      "    [\n",
      "      688.0,\n",
      "      313.0\n",
      "    ]\n",
      "  ],\n",
      "  \"image\": \"015601864.jpg\",\n",
      "  \"scale\": 3.021046,\n",
      "  \"center\": [\n",
      "    594.0,\n",
      "    257.0\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open(TRAIN_JSON) as train_json:\n",
    "    train_annos = json.load(train_json)\n",
    "    json_formatted_str = json.dumps(train_annos[0], indent=2)\n",
    "    print(json_formatted_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12216478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def parse_one_annotation(anno, image_dir):\n",
    "    filename = anno['image']\n",
    "    joints = anno['joints']\n",
    "    joints_visibility = anno['joints_vis']\n",
    "    annotation = {\n",
    "        'filename': filename,\n",
    "        'filepath': os.path.join(image_dir, filename),\n",
    "        'joints_visibility': joints_visibility,\n",
    "        'joints': joints,\n",
    "        'center': anno['center'],\n",
    "        'scale' : anno['scale']\n",
    "    }\n",
    "    return annotation\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3f8b655",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filename': '015601864.jpg', 'filepath': '/aiffel/aiffel/aiffel_quest/images/015601864.jpg', 'joints_visibility': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'joints': [[620.0, 394.0], [616.0, 269.0], [573.0, 185.0], [647.0, 188.0], [661.0, 221.0], [656.0, 231.0], [610.0, 187.0], [647.0, 176.0], [637.0201, 189.8183], [695.9799, 108.1817], [606.0, 217.0], [553.0, 161.0], [601.0, 167.0], [692.0, 185.0], [693.0, 240.0], [688.0, 313.0]], 'center': [594.0, 257.0], 'scale': 3.021046}\n"
     ]
    }
   ],
   "source": [
    "with open(TRAIN_JSON) as train_json:\n",
    "    train_annos = json.load(train_json)\n",
    "    test = parse_one_annotation(train_annos[0], IMAGE_PATH)\n",
    "    print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed55407",
   "metadata": {},
   "source": [
    "##TFRecord 파일 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a46ba60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def generate_tfexample(anno):\n",
    "\n",
    "    # byte 인코딩을 위한 함수\n",
    "    def _bytes_feature(value):\n",
    "        if isinstance(value, type(tf.constant(0))):\n",
    "            value = value.numpy()\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "    filename = anno['filename']\n",
    "    filepath = anno['filepath']\n",
    "    with open(filepath, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = Image.open(filepath)\n",
    "    if image.format != 'JPEG' or image.mode != 'RGB':\n",
    "        image_rgb = image.convert('RGB')\n",
    "        with io.BytesIO() as output:\n",
    "            image_rgb.save(output, format=\"JPEG\", quality=95)\n",
    "            content = output.getvalue()\n",
    "\n",
    "    width, height = image.size\n",
    "    depth = 3\n",
    "\n",
    "    c_x = int(anno['center'][0])\n",
    "    c_y = int(anno['center'][1])\n",
    "    scale = anno['scale']\n",
    "\n",
    "    x = [\n",
    "        int(joint[0]) if joint[0] >= 0 else int(joint[0]) \n",
    "        for joint in anno['joints']\n",
    "    ]\n",
    "    y = [\n",
    "        int(joint[1]) if joint[1] >= 0 else int(joint[0]) \n",
    "        for joint in anno['joints']\n",
    "    ]\n",
    "\n",
    "    v = [0 if joint_v == 0 else 2 for joint_v in anno['joints_visibility']]\n",
    "\n",
    "    feature = {\n",
    "        'image/height':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
    "        'image/width':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
    "        'image/depth':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[depth])),\n",
    "        'image/object/parts/x':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=x)),\n",
    "        'image/object/parts/y':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=y)),\n",
    "        'image/object/center/x': \n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[c_x])),\n",
    "        'image/object/center/y': \n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[c_y])),\n",
    "        'image/object/scale':\n",
    "        tf.train.Feature(float_list=tf.train.FloatList(value=[scale])),\n",
    "        'image/object/parts/v':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=v)),\n",
    "        'image/encoded':\n",
    "        _bytes_feature(content),\n",
    "        'image/filename':\n",
    "        _bytes_feature(filename.encode())\n",
    "    }\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca5c610a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def chunkify(l, n):\n",
    "    size = len(l) // n\n",
    "    start = 0\n",
    "    results = []\n",
    "    for i in range(n):\n",
    "        results.append(l[start:start + size])\n",
    "        start += size\n",
    "    return results\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01df32a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "64\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "test_chunks = chunkify([0] * 1000, 64)\n",
    "print(test_chunks)\n",
    "print(len(test_chunks))\n",
    "print(len(test_chunks[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d518d33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "@ray.remote\n",
    "def build_single_tfrecord(chunk, path):\n",
    "    print('start to build tf records for ' + path)\n",
    "\n",
    "    with tf.io.TFRecordWriter(path) as writer:\n",
    "        for anno in chunk:\n",
    "            tf_example = generate_tfexample(anno)\n",
    "            writer.write(tf_example.SerializeToString())\n",
    "\n",
    "    print('finished building tf records for ' + path)\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5b1debd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def build_tf_records(annotations, total_shards, split):\n",
    "    chunks = chunkify(annotations, total_shards)\n",
    "    futures = [\n",
    "        build_single_tfrecord.remote(\n",
    "            chunk, '{}/{}_{}_of_{}.tfrecords'.format(\n",
    "                TFRECORD_PATH,\n",
    "                split,\n",
    "                str(i + 1).zfill(4),\n",
    "                str(total_shards).zfill(4),\n",
    "            )) for i, chunk in enumerate(chunks)\n",
    "    ]\n",
    "    ray.get(futures)\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2205850c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 14:11:44,740\tWARNING services.py:1729 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=0.84gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to parse annotations.\n",
      "First train annotation:  {'filename': '015601864.jpg', 'filepath': '/aiffel/aiffel/aiffel_quest/images/015601864.jpg', 'joints_visibility': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'joints': [[620.0, 394.0], [616.0, 269.0], [573.0, 185.0], [647.0, 188.0], [661.0, 221.0], [656.0, 231.0], [610.0, 187.0], [647.0, 176.0], [637.0201, 189.8183], [695.9799, 108.1817], [606.0, 217.0], [553.0, 161.0], [601.0, 167.0], [692.0, 185.0], [693.0, 240.0], [688.0, 313.0]], 'center': [594.0, 257.0], 'scale': 3.021046}\n",
      "First val annotation:  {'filename': '005808361.jpg', 'filepath': '/aiffel/aiffel/aiffel_quest/images/005808361.jpg', 'joints_visibility': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'joints': [[804.0, 711.0], [816.0, 510.0], [908.0, 438.0], [1040.0, 454.0], [906.0, 528.0], [883.0, 707.0], [974.0, 446.0], [985.0, 253.0], [982.7591, 235.9694], [962.2409, 80.0306], [869.0, 214.0], [798.0, 340.0], [902.0, 253.0], [1067.0, 253.0], [1167.0, 353.0], [1142.0, 478.0]], 'center': [966.0, 340.0], 'scale': 4.718488}\n",
      "Start to build TF Records.\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=131)\u001b[0m start to build tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0002_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=130)\u001b[0m start to build tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0001_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=130)\u001b[0m finished building tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0001_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=130)\u001b[0m start to build tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0003_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=131)\u001b[0m finished building tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0002_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=131)\u001b[0m start to build tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0004_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=130)\u001b[0m finished building tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0003_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=130)\u001b[0m start to build tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0005_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=131)\u001b[0m finished building tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0004_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=131)\u001b[0m start to build tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0006_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=131)\u001b[0m finished building tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0006_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=131)\u001b[0m start to build tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0007_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=130)\u001b[0m finished building tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0005_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=130)\u001b[0m start to build tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0008_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=131)\u001b[0m finished building tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0007_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=131)\u001b[0m start to build tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0010_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=130)\u001b[0m finished building tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0008_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=130)\u001b[0m start to build tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0009_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=131)\u001b[0m finished building tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0010_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=131)\u001b[0m start to build tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0011_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=130)\u001b[0m finished building tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0009_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=130)\u001b[0m start to build tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0012_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=131)\u001b[0m finished building tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0011_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=131)\u001b[0m start to build tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0013_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=130)\u001b[0m finished building tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0012_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=130)\u001b[0m start to build tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0014_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=131)\u001b[0m finished building tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0013_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=131)\u001b[0m start to build tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0015_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=130)\u001b[0m finished building tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0014_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=130)\u001b[0m start to build tf records for /aiffel/aiffel/aiffel_quest/tfrecords_mpii/train_0016_of_0064.tfrecords\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "ray.init(ignore_reinit_error=True)\n",
    "\n",
    "num_train_shards = 64\n",
    "num_val_shards = 8\n",
    "\n",
    "print('Start to parse annotations.')\n",
    "if not os.path.exists(TFRECORD_PATH):\n",
    "    os.makedirs(TFRECORD_PATH)\n",
    "\n",
    "with open(TRAIN_JSON) as train_json:\n",
    "    train_annos = json.load(train_json)\n",
    "    train_annotations = [\n",
    "        parse_one_annotation(anno, IMAGE_PATH)\n",
    "        for anno in train_annos\n",
    "    ]\n",
    "    print('First train annotation: ', train_annotations[0])\n",
    "\n",
    "with open(VALID_JSON) as val_json:\n",
    "    val_annos = json.load(val_json)\n",
    "    val_annotations = [\n",
    "        parse_one_annotation(anno, IMAGE_PATH) \n",
    "        for anno in val_annos\n",
    "    ]\n",
    "    print('First val annotation: ', val_annotations[0])\n",
    "    \n",
    "print('Start to build TF Records.')\n",
    "build_tf_records(train_annotations, num_train_shards, 'train')\n",
    "build_tf_records(val_annotations, num_val_shards, 'val')\n",
    "\n",
    "print('Successfully wrote {} annotations to TF Records.'.format(\n",
    "    len(train_annotations) + len(val_annotations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d4bedf",
   "metadata": {},
   "source": [
    "##data label 로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dff187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfexample(example):\n",
    "    image_feature_description = {\n",
    "        'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/object/parts/x': tf.io.VarLenFeature(tf.int64),\n",
    "        'image/object/parts/y': tf.io.VarLenFeature(tf.int64),\n",
    "        'image/object/parts/v': tf.io.VarLenFeature(tf.int64),\n",
    "        'image/object/center/x': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/object/center/y': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/object/scale': tf.io.FixedLenFeature([], tf.float32),\n",
    "        'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    return tf.io.parse_single_example(example, image_feature_description)\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a419e827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_roi(image, features, margin=0.2):\n",
    "    img_shape = tf.shape(image)\n",
    "    img_height = img_shape[0]\n",
    "    img_width = img_shape[1]\n",
    "    img_depth = img_shape[2]\n",
    "\n",
    "    keypoint_x = tf.cast(tf.sparse.to_dense(features['image/object/parts/x']), dtype=tf.int32)\n",
    "    keypoint_y = tf.cast(tf.sparse.to_dense(features['image/object/parts/y']), dtype=tf.int32)\n",
    "    center_x = features['image/object/center/x']\n",
    "    center_y = features['image/object/center/y']\n",
    "    body_height = features['image/object/scale'] * 200.0\n",
    "\n",
    "    # keypoint 중 유효한값(visible = 1) 만 사용합니다.\n",
    "    masked_keypoint_x = tf.boolean_mask(keypoint_x, keypoint_x > 0)\n",
    "    masked_keypoint_y = tf.boolean_mask(keypoint_y, keypoint_y > 0)\n",
    "\n",
    "    # min, max 값을 찾습니다.\n",
    "    keypoint_xmin = tf.reduce_min(masked_keypoint_x)\n",
    "    keypoint_xmax = tf.reduce_max(masked_keypoint_x)\n",
    "    keypoint_ymin = tf.reduce_min(masked_keypoint_y)\n",
    "    keypoint_ymax = tf.reduce_max(masked_keypoint_y)\n",
    "\n",
    "    # 높이 값을 이용해서 x, y 위치를 재조정 합니다. 박스를 정사각형으로 사용하기 위해 아래와 같이 사용합니다.\n",
    "    xmin = keypoint_xmin - tf.cast(body_height * margin, dtype=tf.int32)\n",
    "    xmax = keypoint_xmax + tf.cast(body_height * margin, dtype=tf.int32)\n",
    "    ymin = keypoint_ymin - tf.cast(body_height * margin, dtype=tf.int32)\n",
    "    ymax = keypoint_ymax + tf.cast(body_height * margin, dtype=tf.int32)\n",
    "\n",
    "    # 이미지 크기를 벗어나는 점을 재조정 해줍니다.\n",
    "    effective_xmin = xmin if xmin > 0 else 0\n",
    "    effective_ymin = ymin if ymin > 0 else 0\n",
    "    effective_xmax = xmax if xmax < img_width else img_width\n",
    "    effective_ymax = ymax if ymax < img_height else img_height\n",
    "    effective_height = effective_ymax - effective_ymin\n",
    "    effective_width = effective_xmax - effective_xmin\n",
    "\n",
    "    image = image[effective_ymin:effective_ymax, effective_xmin:effective_xmax, :]\n",
    "    new_shape = tf.shape(image)\n",
    "    new_height = new_shape[0]\n",
    "    new_width = new_shape[1]\n",
    "\n",
    "    effective_keypoint_x = (keypoint_x - effective_xmin) / new_width\n",
    "    effective_keypoint_y = (keypoint_y - effective_ymin) / new_height\n",
    "\n",
    "    return image, effective_keypoint_x, effective_keypoint_y\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be54f6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_2d_guassian(height, width, y0, x0, visibility=2, sigma=1, scale=12):\n",
    "    heatmap = tf.zeros((height, width))\n",
    "\n",
    "    xmin = x0 - 3 * sigma\n",
    "    ymin = y0 - 3 * sigma\n",
    "    xmax = x0 + 3 * sigma\n",
    "    ymax = y0 + 3 * sigma\n",
    "    \n",
    "    if xmin >= width or ymin >= height or xmax < 0 or ymax < 0 or visibility == 0:\n",
    "        return heatmap\n",
    "\n",
    "    size = 6 * sigma + 1\n",
    "    x, y = tf.meshgrid(tf.range(0, 6 * sigma + 1, 1), tf.range(0, 6 * sigma + 1, 1), indexing='xy')\n",
    "\n",
    "    center_x = size // 2\n",
    "    center_y = size // 2\n",
    "\n",
    "    gaussian_patch = tf.cast(tf.math.exp(\n",
    "        -(tf.math.square(x - center_x) + tf.math.square(y - center_y)) / (tf.math.square(sigma) * 2)) * scale,\n",
    "                             dtype=tf.float32)\n",
    "\n",
    "    patch_xmin = tf.math.maximum(0, -xmin)\n",
    "    patch_ymin = tf.math.maximum(0, -ymin)\n",
    "    patch_xmax = tf.math.minimum(xmax, width) - xmin\n",
    "    patch_ymax = tf.math.minimum(ymax, height) - ymin\n",
    "\n",
    "    heatmap_xmin = tf.math.maximum(0, xmin)\n",
    "    heatmap_ymin = tf.math.maximum(0, ymin)\n",
    "    heatmap_xmax = tf.math.minimum(xmax, width)\n",
    "    heatmap_ymax = tf.math.minimum(ymax, height)\n",
    "\n",
    "    indices = tf.TensorArray(tf.int32, 1, dynamic_size=True)\n",
    "    updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for j in tf.range(patch_ymin, patch_ymax):\n",
    "        for i in tf.range(patch_xmin, patch_xmax):\n",
    "            indices = indices.write(count, [heatmap_ymin + j, heatmap_xmin + i])\n",
    "            updates = updates.write(count, gaussian_patch[j][i])\n",
    "            count += 1\n",
    "\n",
    "    heatmap = tf.tensor_scatter_nd_update(heatmap, indices.stack(), updates.stack())\n",
    "\n",
    "    return heatmap\n",
    "\n",
    "def make_heatmaps(features, keypoint_x, keypoint_y, heatmap_shape):\n",
    "    v = tf.cast(tf.sparse.to_dense(features['image/object/parts/v']), dtype=tf.float32)\n",
    "    x = tf.cast(tf.math.round(keypoint_x * heatmap_shape[0]), dtype=tf.int32)\n",
    "    y = tf.cast(tf.math.round(keypoint_y * heatmap_shape[1]), dtype=tf.int32)\n",
    "\n",
    "    num_heatmap = heatmap_shape[2]\n",
    "    heatmap_array = tf.TensorArray(tf.float32, 16)\n",
    "\n",
    "    for i in range(num_heatmap):\n",
    "        gaussian = self.generate_2d_guassian(heatmap_shape[1], heatmap_shape[0], y[i], x[i], v[i])\n",
    "        heatmap_array = heatmap_array.write(i, gaussian)\n",
    "\n",
    "    heatmaps = heatmap_array.stack()\n",
    "    heatmaps = tf.transpose(heatmaps, perm=[1, 2, 0])  # change to (64, 64, 16)\n",
    "\n",
    "    return heatmaps\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f27246",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor(object):\n",
    "    def __init__(self,\n",
    "                 image_shape=(256, 256, 3),\n",
    "                 heatmap_shape=(64, 64, 16),\n",
    "                 is_train=False):\n",
    "        self.is_train = is_train\n",
    "        self.image_shape = image_shape\n",
    "        self.heatmap_shape = heatmap_shape\n",
    "\n",
    "    def __call__(self, example):\n",
    "        features = self.parse_tfexample(example)\n",
    "        image = tf.io.decode_jpeg(features['image/encoded'])\n",
    "\n",
    "        if self.is_train:\n",
    "            random_margin = tf.random.uniform([1], 0.1, 0.3)[0]\n",
    "            image, keypoint_x, keypoint_y = self.crop_roi(image, features, margin=random_margin)\n",
    "            image = tf.image.resize(image, self.image_shape[0:2])\n",
    "        else:\n",
    "            image, keypoint_x, keypoint_y = self.crop_roi(image, features)\n",
    "            image = tf.image.resize(image, self.image_shape[0:2])\n",
    "\n",
    "        image = tf.cast(image, tf.float32) / 127.5 - 1\n",
    "        heatmaps = self.make_heatmaps(features, keypoint_x, keypoint_y, self.heatmap_shape)\n",
    "\n",
    "        return image, heatmaps\n",
    "\n",
    "        \n",
    "    def crop_roi(self, image, features, margin=0.2):\n",
    "        img_shape = tf.shape(image)\n",
    "        img_height = img_shape[0]\n",
    "        img_width = img_shape[1]\n",
    "        img_depth = img_shape[2]\n",
    "\n",
    "        keypoint_x = tf.cast(tf.sparse.to_dense(features['image/object/parts/x']), dtype=tf.int32)\n",
    "        keypoint_y = tf.cast(tf.sparse.to_dense(features['image/object/parts/y']), dtype=tf.int32)\n",
    "        center_x = features['image/object/center/x']\n",
    "        center_y = features['image/object/center/y']\n",
    "        body_height = features['image/object/scale'] * 200.0\n",
    "        \n",
    "        masked_keypoint_x = tf.boolean_mask(keypoint_x, keypoint_x > 0)\n",
    "        masked_keypoint_y = tf.boolean_mask(keypoint_y, keypoint_y > 0)\n",
    "        \n",
    "        keypoint_xmin = tf.reduce_min(masked_keypoint_x)\n",
    "        keypoint_xmax = tf.reduce_max(masked_keypoint_x)\n",
    "        keypoint_ymin = tf.reduce_min(masked_keypoint_y)\n",
    "        keypoint_ymax = tf.reduce_max(masked_keypoint_y)\n",
    "        \n",
    "        xmin = keypoint_xmin - tf.cast(body_height * margin, dtype=tf.int32)\n",
    "        xmax = keypoint_xmax + tf.cast(body_height * margin, dtype=tf.int32)\n",
    "        ymin = keypoint_ymin - tf.cast(body_height * margin, dtype=tf.int32)\n",
    "        ymax = keypoint_ymax + tf.cast(body_height * margin, dtype=tf.int32)\n",
    "        \n",
    "        effective_xmin = xmin if xmin > 0 else 0\n",
    "        effective_ymin = ymin if ymin > 0 else 0\n",
    "        effective_xmax = xmax if xmax < img_width else img_width\n",
    "        effective_ymax = ymax if ymax < img_height else img_height\n",
    "        effective_height = effective_ymax - effective_ymin\n",
    "        effective_width = effective_xmax - effective_xmin\n",
    "\n",
    "        image = image[effective_ymin:effective_ymax, effective_xmin:effective_xmax, :]\n",
    "        new_shape = tf.shape(image)\n",
    "        new_height = new_shape[0]\n",
    "        new_width = new_shape[1]\n",
    "        \n",
    "        effective_keypoint_x = (keypoint_x - effective_xmin) / new_width\n",
    "        effective_keypoint_y = (keypoint_y - effective_ymin) / new_height\n",
    "        \n",
    "        return image, effective_keypoint_x, effective_keypoint_y\n",
    "        \n",
    "    \n",
    "    def generate_2d_guassian(self, height, width, y0, x0, visibility=2, sigma=1, scale=12):\n",
    "        \n",
    "        heatmap = tf.zeros((height, width))\n",
    "\n",
    "        xmin = x0 - 3 * sigma\n",
    "        ymin = y0 - 3 * sigma\n",
    "        xmax = x0 + 3 * sigma\n",
    "        ymax = y0 + 3 * sigma\n",
    "\n",
    "        if xmin >= width or ymin >= height or xmax < 0 or ymax <0 or visibility == 0:\n",
    "            return heatmap\n",
    "\n",
    "        size = 6 * sigma + 1\n",
    "        x, y = tf.meshgrid(tf.range(0, 6*sigma+1, 1), tf.range(0, 6*sigma+1, 1), indexing='xy')\n",
    "\n",
    "        center_x = size // 2\n",
    "        center_y = size // 2\n",
    "\n",
    "        gaussian_patch = tf.cast(tf.math.exp(-(tf.square(x - center_x) + tf.math.square(y - center_y)) / (tf.math.square(sigma) * 2)) * scale, dtype=tf.float32)\n",
    "\n",
    "        patch_xmin = tf.math.maximum(0, -xmin)\n",
    "        patch_ymin = tf.math.maximum(0, -ymin)\n",
    "        patch_xmax = tf.math.minimum(xmax, width) - xmin\n",
    "        patch_ymax = tf.math.minimum(ymax, height) - ymin\n",
    "\n",
    "        heatmap_xmin = tf.math.maximum(0, xmin)\n",
    "        heatmap_ymin = tf.math.maximum(0, ymin)\n",
    "        heatmap_xmax = tf.math.minimum(xmax, width)\n",
    "        heatmap_ymax = tf.math.minimum(ymax, height)\n",
    "\n",
    "        indices = tf.TensorArray(tf.int32, 1, dynamic_size=True)\n",
    "        updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for j in tf.range(patch_ymin, patch_ymax):\n",
    "            for i in tf.range(patch_xmin, patch_xmax):\n",
    "                indices = indices.write(count, [heatmap_ymin+j, heatmap_xmin+i])\n",
    "                updates = updates.write(count, gaussian_patch[j][i])\n",
    "                count += 1\n",
    "                \n",
    "        heatmap = tf.tensor_scatter_nd_update(heatmap, indices.stack(), updates.stack())\n",
    "\n",
    "        return heatmap\n",
    "\n",
    "\n",
    "    def make_heatmaps(self, features, keypoint_x, keypoint_y, heatmap_shape):\n",
    "        v = tf.cast(tf.sparse.to_dense(features['image/object/parts/v']), dtype=tf.float32)\n",
    "        x = tf.cast(tf.math.round(keypoint_x * heatmap_shape[0]), dtype=tf.int32)\n",
    "        y = tf.cast(tf.math.round(keypoint_y * heatmap_shape[1]), dtype=tf.int32)\n",
    "        \n",
    "        num_heatmap = heatmap_shape[2]\n",
    "        heatmap_array = tf.TensorArray(tf.float32, 16)\n",
    "\n",
    "        for i in range(num_heatmap):\n",
    "            gaussian = self.generate_2d_guassian(heatmap_shape[1], heatmap_shape[0], y[i], x[i], v[i])\n",
    "            heatmap_array = heatmap_array.write(i, gaussian)\n",
    "        \n",
    "        heatmaps = heatmap_array.stack()\n",
    "        heatmaps = tf.transpose(heatmaps, perm=[1, 2, 0]) # change to (64, 64, 16)\n",
    "        \n",
    "        return heatmaps\n",
    "\n",
    "    def parse_tfexample(self, example):\n",
    "        image_feature_description = {\n",
    "            'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/object/parts/x': tf.io.VarLenFeature(tf.int64),\n",
    "            'image/object/parts/y': tf.io.VarLenFeature(tf.int64),\n",
    "            'image/object/parts/v': tf.io.VarLenFeature(tf.int64),\n",
    "            'image/object/center/x': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/object/center/y': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/object/scale': tf.io.FixedLenFeature([], tf.float32),\n",
    "            'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "            'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
    "        }\n",
    "        return tf.io.parse_single_example(example,\n",
    "                                          image_feature_description)\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c222bd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BottleneckBlock(inputs, filters, strides=1, downsample=False, name=None):\n",
    "    identity = inputs\n",
    "    if downsample:\n",
    "        identity = Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=1,\n",
    "            strides=strides,\n",
    "            padding='same',\n",
    "            kernel_initializer='he_normal')(inputs)\n",
    "\n",
    "    x = BatchNormalization(momentum=0.9)(inputs)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(\n",
    "        filters=filters // 2,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(x)\n",
    "\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(\n",
    "        filters=filters // 2,\n",
    "        kernel_size=3,\n",
    "        strides=strides,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(x)\n",
    "\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(\n",
    "        filters=filters,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(x)\n",
    "\n",
    "    x = Add()([identity, x])\n",
    "    return x\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1b39ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HourglassModule(inputs, order, filters, num_residual):\n",
    "    \n",
    "    up1 = BottleneckBlock(inputs, filters, downsample=False)\n",
    "    for i in range(num_residual):\n",
    "        up1 = BottleneckBlock(up1, filters, downsample=False)\n",
    "\n",
    "    low1 = MaxPool2D(pool_size=2, strides=2)(inputs)\n",
    "    for i in range(num_residual):\n",
    "        low1 = BottleneckBlock(low1, filters, downsample=False)\n",
    "\n",
    "    low2 = low1\n",
    "    if order > 1:\n",
    "        low2 = HourglassModule(low1, order - 1, filters, num_residual)\n",
    "    else:\n",
    "        for i in range(num_residual):\n",
    "            low2 = BottleneckBlock(low2, filters, downsample=False)\n",
    "\n",
    "    low3 = low2\n",
    "    for i in range(num_residual):\n",
    "        low3 = BottleneckBlock(low3, filters, downsample=False)\n",
    "\n",
    "    up2 = UpSampling2D(size=2)(low3)\n",
    "\n",
    "    return up2 + up1\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4235f746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearLayer(inputs, filters):\n",
    "    x = Conv2D(\n",
    "        filters=filters,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(inputs)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = ReLU()(x)\n",
    "    return x\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66c76a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def StackedHourglassNetwork(\n",
    "        input_shape=(256, 256, 3), \n",
    "        num_stack=4, \n",
    "        num_residual=1,\n",
    "        num_heatmap=16):\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=7,\n",
    "        strides=2,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(inputs)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BottleneckBlock(x, 128, downsample=True)\n",
    "    x = MaxPool2D(pool_size=2, strides=2)(x)\n",
    "    x = BottleneckBlock(x, 128, downsample=False)\n",
    "    x = BottleneckBlock(x, 256, downsample=True)\n",
    "\n",
    "    ys = []\n",
    "    for i in range(num_stack):\n",
    "        x = HourglassModule(x, order=4, filters=256, num_residual=num_residual)\n",
    "        for i in range(num_residual):\n",
    "            x = BottleneckBlock(x, 256, downsample=False)\n",
    "\n",
    "        x = LinearLayer(x, 256)\n",
    "\n",
    "        y = Conv2D(\n",
    "            filters=num_heatmap,\n",
    "            kernel_size=1,\n",
    "            strides=1,\n",
    "            padding='same',\n",
    "            kernel_initializer='he_normal')(x)\n",
    "        ys.append(y)\n",
    "\n",
    "        if i < num_stack - 1:\n",
    "            y_intermediate_1 = Conv2D(filters=256, kernel_size=1, strides=1)(x)\n",
    "            y_intermediate_2 = Conv2D(filters=256, kernel_size=1, strides=1)(y)\n",
    "            x = Add()([y_intermediate_1, y_intermediate_2])\n",
    "\n",
    "    return tf.keras.Model(inputs, ys, name='stacked_hourglass')\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68566cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Simplebaseline(input_shape=(256, 256, 3)):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # ResNet50을 통과시킨 후 특징 맵 추출\n",
    "    x = resnet(inputs)\n",
    "\n",
    "    # 역 컨볼루션 레이어를 통과시킴\n",
    "    x = upconv(x)\n",
    "\n",
    "    # 최종 출력 레이어 적용\n",
    "    out = final_layer(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, out, name='simple_baseline')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ad2b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 epochs,\n",
    "                 global_batch_size,\n",
    "                 strategy,\n",
    "                 initial_learning_rate):\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.strategy = strategy\n",
    "        self.global_batch_size = global_batch_size\n",
    "        self.loss_object = tf.keras.losses.MeanSquaredError(\n",
    "            reduction=tf.keras.losses.Reduction.NONE)\n",
    "        self.optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate=initial_learning_rate)\n",
    "        self.model = model\n",
    "\n",
    "        self.current_learning_rate = initial_learning_rate\n",
    "        self.last_val_loss = math.inf\n",
    "        self.lowest_val_loss = math.inf\n",
    "        self.patience_count = 0\n",
    "        self.max_patience = 10\n",
    "        self.best_model = None\n",
    "\n",
    "    def lr_decay(self):\n",
    "        if self.patience_count >= self.max_patience:\n",
    "            self.current_learning_rate /= 10.0\n",
    "            self.patience_count = 0\n",
    "        elif self.last_val_loss == self.lowest_val_loss:\n",
    "            self.patience_count = 0\n",
    "        self.patience_count += 1\n",
    "\n",
    "        self.optimizer.learning_rate = self.current_learning_rate\n",
    "\n",
    "    def lr_decay_step(self, epoch):\n",
    "        if epoch == 25 or epoch == 50 or epoch == 75:\n",
    "            self.current_learning_rate /= 10.0\n",
    "        self.optimizer.learning_rate = self.current_learning_rate\n",
    "\n",
    "    def compute_loss(self, labels, outputs):\n",
    "        loss = 0\n",
    "        for output in outputs:\n",
    "            weights = tf.cast(labels > 0, dtype=tf.float32) * 81 + 1\n",
    "            loss += tf.math.reduce_mean(\n",
    "                tf.math.square(labels - output) * weights) * (\n",
    "                    1. / self.global_batch_size)\n",
    "        return loss\n",
    "\n",
    "    def train_step(self, inputs):\n",
    "        images, labels = inputs\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = self.model(images, training=True)\n",
    "            loss = self.compute_loss(labels, outputs)\n",
    "\n",
    "        grads = tape.gradient(\n",
    "            target=loss, sources=self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads, self.model.trainable_variables))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def val_step(self, inputs):\n",
    "        images, labels = inputs\n",
    "        outputs = self.model(images, training=False)\n",
    "        loss = self.compute_loss(labels, outputs)\n",
    "        return loss\n",
    "\n",
    "    def run(self, train_dist_dataset, val_dist_dataset):\n",
    "        @tf.function\n",
    "        def distributed_train_epoch(dataset):\n",
    "            tf.print('Start distributed traininng...')\n",
    "            total_loss = 0.0\n",
    "            num_train_batches = 0.0\n",
    "            for one_batch in dataset:\n",
    "                per_replica_loss = self.strategy.run(\n",
    "                    self.train_step, args=(one_batch, ))\n",
    "                batch_loss = self.strategy.reduce(\n",
    "                    tf.distribute.ReduceOp.SUM, per_replica_loss, axis=None)\n",
    "                total_loss += batch_loss\n",
    "                num_train_batches += 1\n",
    "                tf.print('Trained batch', num_train_batches, 'batch loss',\n",
    "                         batch_loss, 'epoch total loss', total_loss / num_train_batches)\n",
    "            return total_loss, num_train_batches\n",
    "\n",
    "        @tf.function\n",
    "        def distributed_val_epoch(dataset):\n",
    "            total_loss = 0.0\n",
    "            num_val_batches = 0.0\n",
    "            for one_batch in dataset:\n",
    "                per_replica_loss = self.strategy.run(\n",
    "                    self.val_step, args=(one_batch, ))\n",
    "                num_val_batches += 1\n",
    "                batch_loss = self.strategy.reduce(\n",
    "                    tf.distribute.ReduceOp.SUM, per_replica_loss, axis=None)\n",
    "                tf.print('Validated batch', num_val_batches, 'batch loss',\n",
    "                         batch_loss)\n",
    "                if not tf.math.is_nan(batch_loss):\n",
    "                    # TODO: Find out why the last validation batch loss become NaN\n",
    "                    total_loss += batch_loss\n",
    "                else:\n",
    "                    num_val_batches -= 1\n",
    "\n",
    "            return total_loss, num_val_batches\n",
    "\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            self.lr_decay()\n",
    "            print('Start epoch {} with learning rate {}'.format(\n",
    "                epoch, self.current_learning_rate))\n",
    "\n",
    "            train_total_loss, num_train_batches = distributed_train_epoch(\n",
    "                train_dist_dataset)\n",
    "            train_loss = train_total_loss / num_train_batches\n",
    "            print('Epoch {} train loss {}'.format(epoch, train_loss))\n",
    "\n",
    "            val_total_loss, num_val_batches = distributed_val_epoch(\n",
    "                val_dist_dataset)\n",
    "            val_loss = val_total_loss / num_val_batches\n",
    "            print('Epoch {} val loss {}'.format(epoch, val_loss))\n",
    "\n",
    "            # save model when reach a new lowest validation loss\n",
    "            if val_loss < self.lowest_val_loss:\n",
    "                self.save_model(epoch, val_loss)\n",
    "                self.lowest_val_loss = val_loss\n",
    "            self.last_val_loss = val_loss\n",
    "\n",
    "        return self.best_model\n",
    "\n",
    "    def save_model(self, epoch, loss):\n",
    "        model_name = MODEL_PATH + '/model-epoch-{}-loss-{:.4f}.h5'.format(epoch, loss)\n",
    "        self.model.save_weights(model_name)\n",
    "        self.best_model = model_name\n",
    "        print(\"Model {} saved.\".format(model_name))\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1017c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (256, 256, 3)\n",
    "HEATMAP_SIZE = (64, 64)\n",
    "\n",
    "def create_dataset(tfrecords, batch_size, num_heatmap, is_train):\n",
    "    preprocess = Preprocessor(\n",
    "        IMAGE_SHAPE, (HEATMAP_SIZE[0], HEATMAP_SIZE[1], num_heatmap), is_train)\n",
    "\n",
    "    dataset = tf.data.Dataset.list_files(tfrecords)\n",
    "    dataset = tf.data.TFRecordDataset(dataset)\n",
    "    dataset = dataset.map(\n",
    "        preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    if is_train:\n",
    "        dataset = dataset.shuffle(batch_size)\n",
    "\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48de510e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#StackedHourglassNetwork\n",
    "def train(epochs, learning_rate, num_heatmap, batch_size, train_tfrecords, val_tfrecords):\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    global_batch_size = strategy.num_replicas_in_sync * batch_size\n",
    "    train_dataset = create_dataset(\n",
    "        train_tfrecords, global_batch_size, num_heatmap, is_train=True)\n",
    "    val_dataset = create_dataset(\n",
    "        val_tfrecords, global_batch_size, num_heatmap, is_train=False)\n",
    "\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        os.makedirs(MODEL_PATH)\n",
    "\n",
    "    with strategy.scope():\n",
    "        train_dist_dataset = strategy.experimental_distribute_dataset(\n",
    "            train_dataset)\n",
    "        val_dist_dataset = strategy.experimental_distribute_dataset(\n",
    "            val_dataset)\n",
    "\n",
    "        model = StackedHourglassNetwork(IMAGE_SHAPE, 4, 1, num_heatmap)\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model,\n",
    "            epochs,\n",
    "            global_batch_size,\n",
    "            strategy,\n",
    "            initial_learning_rate=learning_rate)\n",
    "\n",
    "        print('Start training...')\n",
    "        return trainer.run(train_dist_dataset, val_dist_dataset)\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1950bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''train_tfrecords = os.path.join(TFRECORD_PATH, 'train*')\n",
    "val_tfrecords = os.path.join(TFRECORD_PATH, 'val*')\n",
    "epochs = 5\n",
    "batch_size = 16\n",
    "num_heatmap = 16\n",
    "learning_rate = 0.0007\n",
    "\n",
    "best_model_file = train(epochs, learning_rate, num_heatmap, batch_size, train_tfrecords, val_tfrecords)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b875f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simplebaseline\n",
    "def train_simplebaseline(epochs, learning_rate, num_heatmap, batch_size, train_tfrecords, val_tfrecords):\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    global_batch_size = strategy.num_replicas_in_sync * batch_size\n",
    "    train_dataset = create_dataset(\n",
    "        train_tfrecords, global_batch_size, num_heatmap, is_train=True)\n",
    "    val_dataset = create_dataset(\n",
    "        val_tfrecords, global_batch_size, num_heatmap, is_train=False)\n",
    "\n",
    "    if not os.path.exists(MODEL_SIMPLEBASELINE_PATH):\n",
    "        os.makedirs(MODEL_SIMPLEBASELINE_PATH)\n",
    "\n",
    "    with strategy.scope():\n",
    "        train_dist_dataset = strategy.experimental_distribute_dataset(\n",
    "            train_dataset)\n",
    "        val_dist_dataset = strategy.experimental_distribute_dataset(\n",
    "            val_dataset)\n",
    "\n",
    "        model = Simplebaseline(IMAGE_SHAPE, 4, 1, num_heatmap)\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model,\n",
    "            epochs,\n",
    "            global_batch_size,\n",
    "            strategy,\n",
    "            initial_learning_rate=learning_rate)\n",
    "\n",
    "        print('Start training...')\n",
    "        return trainer.run(train_dist_dataset, val_dist_dataset)\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcbab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfrecords = os.path.join(TFRECORD_PATH, 'train*')\n",
    "val_tfrecords = os.path.join(TFRECORD_PATH, 'val*')\n",
    "epochs = 5\n",
    "batch_size = 16\n",
    "num_heatmap = 16\n",
    "learning_rate = 0.0007\n",
    "\n",
    "best_model_file = train_simplebaseline(epochs, learning_rate, num_heatmap, batch_size, train_tfrecords, val_tfrecords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e97d569",
   "metadata": {},
   "source": [
    "예측 엔진 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2f7b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#StackedHourglassNetwork\n",
    "WEIGHTS_PATH = os.path.join(PROJECT_PATH, 'models', 'model-epoch-5-loss-1.1933.h5')\n",
    "\n",
    "model = StackedHourglassNetwork(IMAGE_SHAPE, 4, 1)\n",
    "model.load_weights(WEIGHTS_PATH)\n",
    "\n",
    "# 이전의 학습하는 코드 블럭을 통해 학습하고 그 모델을 사용할 경우 아래 주석 처리된 코드를 사용하면 됩니다\n",
    "# model.load_weights(best_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c93ced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simplebaseline\n",
    "WEIGHTS_PATH = os.path.join(PROJECT_PATH, 'simplebaseline', '??')\n",
    "\n",
    "model = StackedHourglassNetwork(IMAGE_SHAPE, 4, 1)\n",
    "model.load_weights(WEIGHTS_PATH)\n",
    "\n",
    "# 이전의 학습하는 코드 블럭을 통해 학습하고 그 모델을 사용할 경우 아래 주석 처리된 코드를 사용하면 됩니다\n",
    "# model.load_weights(best_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543d40f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_ANKLE = 0\n",
    "R_KNEE = 1\n",
    "R_HIP = 2\n",
    "L_HIP = 3\n",
    "L_KNEE = 4\n",
    "L_ANKLE = 5\n",
    "PELVIS = 6\n",
    "THORAX = 7\n",
    "UPPER_NECK = 8\n",
    "HEAD_TOP = 9\n",
    "R_WRIST = 10\n",
    "R_ELBOW = 11\n",
    "R_SHOULDER = 12\n",
    "L_SHOULDER = 13\n",
    "L_ELBOW = 14\n",
    "L_WRIST = 15\n",
    "\n",
    "MPII_BONES = [\n",
    "    [R_ANKLE, R_KNEE],\n",
    "    [R_KNEE, R_HIP],\n",
    "    [R_HIP, PELVIS],\n",
    "    [L_HIP, PELVIS],\n",
    "    [L_HIP, L_KNEE],\n",
    "    [L_KNEE, L_ANKLE],\n",
    "    [PELVIS, THORAX],\n",
    "    [THORAX, UPPER_NECK],\n",
    "    [UPPER_NECK, HEAD_TOP],\n",
    "    [R_WRIST, R_ELBOW],\n",
    "    [R_ELBOW, R_SHOULDER],\n",
    "    [THORAX, R_SHOULDER],\n",
    "    [THORAX, L_SHOULDER],\n",
    "    [L_SHOULDER, L_ELBOW],\n",
    "    [L_ELBOW, L_WRIST]\n",
    "]\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85a764f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_coordinates(heatmaps):\n",
    "    flatten_heatmaps = tf.reshape(heatmaps, (-1, 16))\n",
    "    indices = tf.math.argmax(flatten_heatmaps, axis=0)\n",
    "    y = tf.cast(indices / 64, dtype=tf.int64)\n",
    "    x = indices - 64 * y\n",
    "    return tf.stack([x, y], axis=1).numpy()\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145fd0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints_from_heatmap(heatmaps):\n",
    "    max_keypoints = find_max_coordinates(heatmaps)\n",
    "\n",
    "    padded_heatmap = np.pad(heatmaps, [[1,1],[1,1],[0,0]], mode='constant')\n",
    "    adjusted_keypoints = []\n",
    "    for i, keypoint in enumerate(max_keypoints):\n",
    "        max_y = keypoint[1]+1\n",
    "        max_x = keypoint[0]+1\n",
    "        \n",
    "        patch = padded_heatmap[max_y-1:max_y+2, max_x-1:max_x+2, i]\n",
    "        patch[1][1] = 0\n",
    "        \n",
    "        index = np.argmax(patch)\n",
    "        \n",
    "        next_y = index // 3\n",
    "        next_x = index - next_y * 3\n",
    "        delta_y = (next_y - 1) / 4\n",
    "        delta_x = (next_x - 1) / 4\n",
    "        \n",
    "        adjusted_keypoint_x = keypoint[0] + delta_x\n",
    "        adjusted_keypoint_y = keypoint[1] + delta_y\n",
    "        adjusted_keypoints.append((adjusted_keypoint_x, adjusted_keypoint_y))\n",
    "        \n",
    "    adjusted_keypoints = np.clip(adjusted_keypoints, 0, 64)\n",
    "    normalized_keypoints = adjusted_keypoints / 64\n",
    "    return normalized_keypoints\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7c7fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, image_path):\n",
    "    encoded = tf.io.read_file(image_path)\n",
    "    image = tf.io.decode_jpeg(encoded)\n",
    "    inputs = tf.image.resize(image, (256, 256))\n",
    "    inputs = tf.cast(inputs, tf.float32) / 127.5 - 1\n",
    "    inputs = tf.expand_dims(inputs, 0)\n",
    "    outputs = model(inputs, training=False)\n",
    "    if type(outputs) != list:\n",
    "        outputs = [outputs]\n",
    "    heatmap = tf.squeeze(outputs[-1], axis=0).numpy()\n",
    "    kp = extract_keypoints_from_heatmap(heatmap)\n",
    "    return image, kp\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b7fff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints_on_image(image, keypoints, index=None):\n",
    "    fig,ax = plt.subplots(1)\n",
    "    ax.imshow(image)\n",
    "    joints = []\n",
    "    for i, joint in enumerate(keypoints):\n",
    "        joint_x = joint[0] * image.shape[1]\n",
    "        joint_y = joint[1] * image.shape[0]\n",
    "        if index is not None and index != i:\n",
    "            continue\n",
    "        plt.scatter(joint_x, joint_y, s=10, c='red', marker='o')\n",
    "    plt.show()\n",
    "\n",
    "def draw_skeleton_on_image(image, keypoints, index=None):\n",
    "    fig,ax = plt.subplots(1)\n",
    "    ax.imshow(image)\n",
    "    joints = []\n",
    "    for i, joint in enumerate(keypoints):\n",
    "        joint_x = joint[0] * image.shape[1]\n",
    "        joint_y = joint[1] * image.shape[0]\n",
    "        joints.append((joint_x, joint_y))\n",
    "    \n",
    "    for bone in MPII_BONES:\n",
    "        joint_1 = joints[bone[0]]\n",
    "        joint_2 = joints[bone[1]]\n",
    "        plt.plot([joint_1[0], joint_2[0]], [joint_1[1], joint_2[1]], linewidth=5, alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5340da44",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = os.path.join(PROJECT_PATH, 'test_image.jpg')\n",
    "\n",
    "image, keypoints = predict(model, test_image)\n",
    "draw_keypoints_on_image(image, keypoints)\n",
    "draw_skeleton_on_image(image, keypoints)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
