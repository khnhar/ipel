{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaNQF3y3LOK-",
        "outputId": "6effdbeb-bad0-4300-c0cf-418c3b3c9738"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. 시맨틱 세그멘테이션 데이터셋"
      ],
      "metadata": {
        "id": "A3ngI2QsTFYd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###이미지, 데이터 가져오기"
      ],
      "metadata": {
        "id": "2xKYeYWdQIlP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAl4AAACICAYAAAA22eWdAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAABhaVRYdFNuaXBNZXRhZGF0YQAAAAAAeyJjbGlwUG9pbnRzIjpbeyJ4IjowLCJ5IjowfSx7IngiOjYwNiwieSI6MH0seyJ4Ijo2MDYsInkiOjEzNn0seyJ4IjowLCJ5IjoxMzZ9XX0Zk65GAAAcBklEQVR4Xu3df2wU14EH8O/aQEjhmgBNjU16UYiXqBEysh0lyEjV/RE5eHFa3x9HQTmdi861pRPY/HGovhhF1QnHrpBOtoVOwrUU9o8oLepVqHLWsVWpPyRQiACfLUQS1oGYSl5vCFhX2oJ/rOfem3m7Ozs7M/sLhnX8/UgvO/PmvTeL/8lX7z0/+zQBRERERPTIlahPIiIiInrEGLyIiIiIPMLgRUREROQRBi8iIiIijzB4EREREXmEwYuIiIjIIwxeRERERB5h8CIiIiLyCIMXERERkUcYvIiIiIg8wuBFRERE5JGC/1bj0tIS/nRrGrdv3xaj+VRtkqwp27oV27Y9i9LSUqOSiIiIaBUqOHg9ePAAkZkZfPOpp7BhwwZVmzQ9/QU++/QaqqqqUbFtG9atW6eeEBEREa0uD2WpsaSkRJ/Nsitr167FM8+UYWFhQQ9hi4uLqhcRERHR6vJQZryis7N46umnbWe8bomw9ckn17Bp02ZEIjOorNyBql279LBGRERERWYyiPahy+rGUNsygOYqdeMgOtaLd3EInfVlqobsPPLgNT8/j3v37umzX0tLi7j08UU07HtDnwlLN4X+Pc1A8Dw6KlWVTtafxI7zp9GgaoARtPkCGFR3qOtD+HwHKvW2fhy9oOqFur4wxCOjHvF2cWKcPddxLFGXOq7RVz5xGjflixIRUZGTAaF7eEbd1aJloBnJTDGJYPsQjNhRgcauTsRzRL797Lm0NwefikZ0ddbDfahM7aMY6+1GJJA5POljhcotYxjfVfyDU/vbBDQrt8A2GWxHSvfaFgzYNHZrl+0YRUUGr0Lcv39f++LmTW1ubk5bWFjIWH79q19qC/PzqrdVWOurq9P6wuo2Qda3aiF1p4VaRVi0tBN1rXoDS9sEo761FapdXEhrresTT9W1ZdxQX/yZ07hERLRyTGhnzkyoa2HijHakZ1Sb1W9mtdGeI1risXx25Izood/k2c9O9u+ZOHNE6xk13mLPvf3saI8Yu0e0EcX5Cynye/Votq+bHdV6Mg+QkwnxnVz/aYpbu2zHKCaPYb0v/TcfczOCtsBV9IUts2INp3E6OR3mqOlYH64G2sQoNqau42rdfuwzjdvQYZ4dIyKila0KzeYZkapq1M5EEJXX0QlcQSP2xh9X7UVjRQSz+sN8+9nI4T1V1bWYiTgNJLm3L6vvxMBAJ/aWq4qHTs6mtaO93VJ6x4yfjaMoZiPq0io6ht72XozpA7i0c31WvB5D8CpoZVPkrnMYbD1uWYrMQWUHgn1XcaJ/SlWYVO7DfhzFSdtURkREXzvRWUQqyo1ltaj4v3jNLtMSWxl21QC2uSffflIO7SfHI2hMJLTMcm2fqgz1gXIMdwcxqWoMkwh2D6O8On3cyaCxhDkwYCmBCLqDqaOkmxHvsglqZfXoFGExuVTr0E7n9qw4rcAZL6DuJb+6cjKIgM8Hn172wJqxKjuOY+fRkzazXpXoOB/GSydkP7tZMfdxiYhoBZEzK91XUHPI2M8UdZg+iVinrvLtp2RsL/dOqZmj8epMe8WEXNu7qWrGQAswpMYzis3+LqWquQvlIXNbVeQ+MbsOCSLkdSaDWlfNFYeg5tYu2zGKy4r81cIL18LqykkrQpom96+JYt2oLzXgdAgItNlNbcnwJfs14ZwMWCltMo1LREQrgdwo3/4ucMg0s1K21X49rnxrMsnk3E9fNksGEpkLMr5Hhh8VJqrHRb94mLAZS+fUPl9qvK7GClQ0dunXzhkqNfwkSqZfCLAoqw+g9vK4ZaYtnVu7bMd43FZe8GpoQuvgOfs9WrloOIa+qydcZq1EOBMBKwS3NkREtNLI34STxx7YhQPrfiq5KliuGuXVT182SwaSeIBxe49ZVXNLMkw4jGWW0v5RMs2yZSqF5sCvmxU449WAY31XEbAuBY60wXYCy1ElOoL7cfbkOXUvTPWjLSVljeBc4rwKIiJa8aJjCEUacchuPU5uco8MJYOCCBdDkRrskk3z7WfHrb24NgeV6FgIl2urTcdWWOTa3okYxxqY5NEZM8PdafX6+0yzbPFiniEzF/vZskmMGbvndZPBIYfv7dYu2zGKyyM/x8tq+Dfn0PjGD7DW9k8HpZ+VZZzPtQ8fWM/xEkHLFzClotYQNP3XGm3G0J/5Rb31LDA5jA+Bq8mzvab698Bv6twa0tRvSzqNm8WvUhIRUXGQASPt7CnTOVr6/q1hGKd1mc7qyrefE8f2xplbiePCMp7jlV17uUT64dZOlyXDwsl35HKAasoZXObzt/SfzRXUqJ+tYzvB7VmxKrLgRURERCtRrsFrtXoowevWrWk88cQTWQWvP/z+d3jj+038Y9lERES06hQcvGKxGL6MzuKrr75SNe42bNyI559/Hj7fivyFSiIiIqK8FRy8iIiIiCg7nHYiIiIi8giDFxEREZFHGLyIiIiIPMLgRUREROQRBi8iIiIijzB4EREREXmEwYuIiIjIIwxeRERERB5h8CIiIiLyCIMXERERkUcYvIiIiIg8wuBFRERE5BEGLyIiIiKPMHgRERERecSnCeo6L0tLS/jTrWncvn1bjOZTtUmypmzrVmzb9ixKS0uNSiIiIqJVqODg9eDBA0RmZvDNp57Chg0bVG3S9PQX+OzTa6iqqkbFtm1Yt26dekJERES0ujyUpcaSkhJ9NsuurF27Fs88U4aFhQU9hC0uLqpeRERERKvLQ5nxis7O4qmnn7ad8bolwtYnn1zDpk2bEYnMoLJyB6p27dLDGhERERWZySDahy6rG0NtywCaq9SNg+hYL97FIXTWl6kasvPIg9f8/Dzu3bunz34tLS3i0scX0bDvDX0mLN0I2nwBDKo7oA594fPoqJTXU+jf48fRC/oDXV1fGOeNh7qRNh8CCEE73aBqpPR+UmtIQ7KZaoM+hM93IDmiYap/D/xn96tnmb8HEREVLxkQuodn1F0tWgaakcwUkwi2D8GIHRVo7OpEPEfk28+eS3tz8KloRFdnPdyHytQ+irHebkQCmcOTPlao3DKG8V3FPzi1v01As3ILbJPBdqR0r23BgE1jt3bZjlFUZPAqxP3797Uvbt7U5ubmtIWFhYzl17/6pbYwP696W4W0VrSK/yqhVk2kGi2s34S1vjrTszSir3guS2ob2a9O6zMGUeR7oInApO6NNnVp7SQ5rnyW7fcgIqLiNaGdOTOhroWJM9qRnlFtVr+Z1UZ7jmiJx/LZkTOih36TZz872b9n4swRrWfUeIs99/azoz1i7B7RRhTnL6TI79Wj2b5udlTryTxATibEd3L9pylu7bIdo5g8hvW+9N98dNTQhNYL1xBWt65GzuHq/mNo2jmIE/1TqtJJA05rIew8ehIjqgbYif37gaMnkzXSVP8JMe5+8ZSIiFa+KjSbZ0SqqlE7E0FUXkcncAWN2Bt/XLUXjRURzOoP8+1nI4f3VFXXYibiNJDk3r6svhMDA53YW64qHjo5m9aO9nZL6R0zfjaOopiNqEur6Bh623sxpg/g0s71WfF6DMErh5VNEaYGW5tETMpkCv0nBrFzR6XIaq24cPYDUZNJA5paB3HOlLN2dBxH6+A5Uxibwgdnd+J4xw51T0REXyvRWUQqyo1ltaj4v3jNLtMSWxl21QC2uSffflIO7SfHI2hMJLTMcm2fqgz1gXIMdwcxqWoMkwh2D6O8On3cyaCxhDkwYCmBCLqDqaOkmxHvsglqZfXoFGExuVTr0E7n9qw4FeGM1yACPh98spxrsuzXMj3z7UFiYmvqA5y90Iom2VSfJTuLDzInLxtGGEvMmI2cxNGddsHP4XsQEdHKIWdWuq+g5pCxnynqMH0SsU5d5dtPydhe7p1SM0fj1Zn2igm5tndT1YyBFmBIjWcUm/1dSlVzF8pD5raqyH1idh0SRMjrTAa1rporDkHNrV22YxSXIvzVwlaENA1auA91KbNPknqml/ime5m7zuJCYmZMhqcLOJtV8qrDS351qTQc65PrjeK9xixaq57mrOy/BxERrQxyo3z7u8Ah08xK2Vb79bjyrckkk3M/fdksGUhkLsj4Hhl+VJioHhf94mHCZiydU/t8qfG6GitQ0dilXztnqNTwkyiZfiHAoqw+gNrL45aZtnRu7bId43Er3jMdKjsQ7LuKQFtq9Eo3gpPyVwwHA2oGyofAIHAhZf+Wjal+nLi6H/usoUm897hcguz/AGfRh2N2uYuIiFYs+Ztw8tgDu3Bg3U8lVwXLVaO8+unLZslAEg8wbu8xq2puSYYJh7HMUto/SqZZtkyl0Bz4dVO8wUuo1PdcnXBfypP7wOr6EE7MQMkSRl9d6v6tFCNt8PnPYn8w/egISe4TGzx6FNi/z/Y5ERGtUNExhCKNOGS3Hic3uUeGkkFBhIuhSA12yab59rPj1l5cm4NKdCyEy7XVpmMrLHJt70SMYw1M8uiMmeHutHr9faZZtngxz5CZi/1s2STGjN3zusngkMP3dmuX7RjF5ZGf42U1/JtzaHzjB1hr+6eD5Dle59CknU7sq0qeobUPH1jP42oNIYQAzjWZz+RSZLjS94j508/xkkEt5bwueTbXSew4H3+v9V58rz3XcczhHC/5PVL3ohERUVGSASPt7CnTOVr6/q1hGKd1mc7qyrefE8f2xplbiePCMp7jlV17uUT64dZOlyXDwsl35HKAasoZXObzt/SfzRXUqJ+tYzvB7VmxKrLgRURERCtRrsFrtXoowevWrWk88cQTWQWvP/z+d3jj+038Y9lERES06hQcvGKxGL6MzuKrr75SNe42bNyI559/Hj5fUW8vIyIiInroCg5eRERERJQdTjsREREReYTBi4iIiMgjDF5EREREHmHwIiIiIvIIgxcRERGRRxi8iIiIiDzC4EVERETkEQYvIiIiIo8weBERERF5hMGLiIiIyCMMXkREREQeYfAiIiIi8giDFxEREZFHGLyIiIiIPMLgRUREROQRnyao69wtLwL3/hfa0j3ER/Gt2QhsfMn4JCIiIqKEwoLXwm0sX/lHaPNfiuDl06u00s0oefZHKP3OPwMla/S6ND5R7ytVN0RERESrQ0HBS3sQQezCq9CWY3rwkiPJT9+Tz2Htd/4JmghYmrYsKo1iXMeA9duw9tmD4u1c6SQiIioqk0G0D11WN4balgE0V6kbB9GxXryLQ+isL1M1ZKew4LVwG3+7eEAErLUiVIlhlpfhW7Me67d8F6XrNooGS6qIsLW8JNqIT3HvW7cZvu0/tQleU+jf0wwEz6OjUlVlrZC+RES0WsiA0D08o+5q0TLQjGSmmESwfQhG7KhAY1cn4jki3372XNqbg09FI7o66+E+VKb2UYz1diMSyBye9LFC5ZYxjO8q/sGp/W0CmpVbYJsMtiOle20LBmwau7XLdoyiIoNXvpYX72lLt05psS/+S4vdPKnFbvSIckLTvujRtJvi8/OfinJc06Y6NS3875r22VFN+/SwuH5L9I4Zg6QIa311dVpfWN3mpJC+RES0OkxoZ85MqGth4ox2pGdUm9VvZrXRniNa4rF8duSM6KHf5NnPTvbvmThzROsZNd5iz7397GiPGLtHtBHF+Qsp8nv1aLavmx3VejIPkJMJ8Z1c/2mKW7tsxygmBa31+XxAaUkJSkp9EB+iiE9ZubwgyrxIdaLo16LEVJ1exLWN/j1+HL1wAUf9Pvj29GNKVk71Y48Y0ydL24jeThppU3V6OznbZdOXiIgoRRWazTMiVdWonYkgKq+jE7iCRuyNP67ai8aKCGb1h/n2s5HDe6qqazETcRpIcm9fVt+JgYFO7C1XFQ+dnE1rR3u7pfSOGT8bR1HMRtSlVXQMve29GNMHcGnn+qx4FbbJSt/UJYPUoirxcCU/zXXmelEgS7qO82H01dWhL6xBO9+BSoygzX8W++W9eFcIAejZa6RNXIX0Oi24A+GpSpu+REREGURnEakoN5bVouL/4jW7TEtsZdhVA9jmnnz7STm0nxyPoDGR0DLLtX2qMtQHyjHcHcSkqjFMItg9jPLq9HEng8YS5sCApQQi6A6mjpJuRrzLJqiV1aNThMXkUq1DO53bs+JU+O72+EyWDGCauE4UVacHrgfqWnzKEhPX2Rg5h8HW44k9Ww1Nrbh63TKXVdmABqYsIiLKlZxZ6b6CmkPGfqaow/RJxDp1lW8/JWN7uXdKzRyNV2faKybk2t5NVTMGWoAhNZ5RbPZ3KVXNXSgPmduqIveJ2XVIECGvMxnUumquOAQ1t3bZjlFcCgxeckO9ClcyTMVUqDJ/Lt9XgUt9xsSnJj6zMHX9KjAYMJYUZQkM4sK1sEhgpxF+6YRet6efi4pERJQbuVG+/V3gkGlmpWyr/Xpc+dZkksm5n75slgwkMhdkfI8MPypMVI+LfvEwYTOWzql9vtR4XY0VqGjs0q+dM1Rq+EmUTL8QYFFWH0Dt5XHLTFs6t3bZjvG4FR685OxWYsZLlPislrXIIKZfy0AmZ8TUEC4qd+xEXV/YWFKMl9MNxrOO8/r98Wt+Y/mRiIgoC/I34eSxB3bhwLqfSq4KlqtGefXTl82SgSQeYNzeY1bV3JIMEw5jmaW0f5RMs2yZSqE58OumoOAlg8/ywj0jTMVLYnkxPsOliimExRbEp61K7Nh5AXJSS+d/CTh6EolcNdIPOcE11d+fqPO/VKeWHy19iYiIrKJjCEUacchuPU5uco8MJYOCCBdDkRrskk3z7WfHrb24NgeV6FgIl2urTcdWWOTa3okYxxqY5NEZM8PdafX6+0yzbPFiniEzF/vZskmMGbvndZPBIYfv7dYu2zGKS2HneC39FfOfn4Z2fxZafApLToKp2SmjSl3HP0VZs7kGT1b+C3x2B6iOtOlLiqjrQ1huko/fS60hNeM1gjZfAHptvJ28tvaVdURERHEyYKSdPWU6R0vfvzUM47Qu01ld+fZz4tjeOHMrcVxYxnO8smsvl0g/3NrpsmRYOPmOXA5QTTmDy3z+lv6zuYIa9bN1bCe4PStWhf3JIBmmFv8istSSuheyGM1Xuh6+NU+qOyIiIlrpcg1eq1WBwYuIiIiIslX4cRJERERElBUGLyIiIiKPMHgREREReYTBi4iIiMgjDF5EREREHmHwIiIiIvIIgxcRERGRRxi8iIiIiDzC4EVERETkEQYvIiIiIo8weBERERF5JKe/1Xjv3j18+eWXiMViqoaIiIiIspXTjBdDFxEREVH+cgpeDF1ERERE+eMeLyIiIiKPMHgREREReYTBi4iIiMgjOf1W4/Xr19WVwactYf3ip/At/xXxUbSSb2B+7Qv6JxERERElFRS8SmN3se12u/6paT69bglP4c8bm/CXb74BzVeq16XxrYHGyTYiIiJaZQoLXku38feRA4C2rAcvOZL8XF73LJa+1SiClwhY4pl8brSRnzHM+76FPz9ZL97O8EVERFRUboziVCisbgz+wGG8vl3dOJi79D4+xF4cfHmTqiE7hQWv5TmUffkfQMk6EarEMMvL8K1Zj/VbvovSdRtFyFpSJSaeLYk24lPcL2Ijpkt+ZBO8phE88BPgZ79A83OqKhvTQRyoH0HDWI79iIho1ZEB4b2P7qg7PwKHX0cyU9zA6KkQjNixBbvfPIh4jsi3nz2X9ubgs2U33jz4MtyHytR+Dpfefw93Xs0cnvSxLm6xjGF8V/EPTu1vE9Cs3ALbjdFTSOnuD+CwTWO3dtmOUUwKC154gOfW/xEl2qIRrmTIQgwlJaWJsCUXHxMBTN6LzyXtG7hRckg8e0jBi4iIKCsiRIwCr8f/55wSNCwBRQ8WMm/IgJVvPzvZv0cGi4tb3nSZRXJvb4RFkUf84sZ/0DEEGeT3+hDYaxMa5y7h/Y8346D7ADm5Mfo+7r6SKaC6t8t2jGJS0FqfzyfCV0kJSkp9ImyJwUrEp6xcXhBlXoQsUfRrUWKqTi/i2kbwQD3eGR/HO/Uv4sUDQUzLmSzxGXxb3L/4Nv4oG/3xbXEt71/EgeC03k9U4u34c3UdDB5ItHvbeEBERKve9mR4krb74b9zR0QOYe5zhLEbr8Qfb38Fu7fcxV39Yb79bOTwnu0iMd254zSQ5N5+08sHcfjwQbyyRVU8dDKsncKpU5by/iXjZ+NoDnfvqksrGfJOvY9L+gAu7VyfFa/CNlnpm7pkkFpUJR6u5Ke5zlwvCmRJ1/yLMbxVXY23xj7DZ79ohj7pNf4OPn9N3H/2n/ienBG7+Zq4lvc/x453foJE9krxS4zgZ0a7sbdw/cfxUEZERGQyJwLPli3GstrcHcD/gmmJbRNe8AO2uSffflIO7W+E72J3IqFllmv7VJvw8qub8dF7o7ihagw3MPreR9jsTx/3xqgxc3f4sKW8egfvjaaOku6OeJdNUNv0Mg6KsJicxXJop3N7VpwKC15SfCZLBjBNXCeKqtMD1wN1LT5liYnrrP0Qr31PXYoo1twcv/keXvuhukzzQ/xbfK3yuX9AQ/V13LQNaEREtGrJmZX3wvDvNfYzzTlMn9y1Tl3l20/J2F4uPaqZo7A/i2W0XNu72f46DgeAkBrPKDb7u5Ttr7+JLRfNbVWRy7B2HRJEyDuYDGpv+sMOQc2tXbZjFJcCg5fcUK/ClQxTMRWqzJ/L91XgUp8x8amJz2xVv2DMfMWZlhp//EtVR0RElAO59+mU3M5kmlnZtHmzcWGxeXMyyeTcT182SwYSmQsyvkeGHxUm/GHRLx4mbMbSObXPlxrvzd1bsGX3m/q1c4ZKDT+JkukXAiw2vfyq+O5hy0xbOrd22Y7xuBUevOTsVmLGS5T4rJa1yCCmX8tAJmfE1BC5kKHrt/Glxs/wc8cZLyIiIntyA7o89sAuHFj3U8lVwS2qUV799GWzZCCJBxi395htfz2QDBMOY5mltH+UTLNsmcoKmITyVEHBS/5C5PLCPSNMxUtieTE+w6WKKYTFFsSnrefw/I5xfO6wLDh98zqqX1DzX9NB/DdnvIiIKBdzl3Dx7m7stVuPk5vc74aSQUGEi9BdP16QTfPtZ8etvbg2B5W5SxcR9vvhOOGUa3snYhxrYJJHZ9z56L20ev19plm2eDHPkJmL/WzZDVwyds/rboyGHL63W7tsxyguhf3JIBGu/u7//gdrlu5Ai09hyUkwMaQ+rF6lruOfoiw++V3c39wIn90BqnJWS64hVr+FsZ8BP9FPl1Ab7fXfWPwx9Lwlnr+1YwT4V3n0hKz/LV7TN+CbryUeUUFERIoMGGlnT5nO0dL3b32EO3q96ayufPs5cWxvHDWROC4s4zle2bWXS6Qfb850nERh5DtyOUA15Qwu8/lb+s8mDL/62Tq2E9yeFauCgpcMU77Y38RnzLiVshmt5AloohAREdHXQ67Ba7UqMHgRERERUbYKP06CiIiIiLLC4EVERETkEQYvIiIiIo8weBERERF5hMGLiIiIyCM5Ba/S0lJ1RURERES5yil4ffvb32b4IiIiIspTTud4EREREVH+uMeLiIiIyCMMXkREREQeYfAiIiIi8giDFxEREZFHGLyIiIiIPMLgRUREROQRBi8iIiIijzB4EREREXkC+H/vnF42OXp3fAAAAABJRU5ErkJggg==)\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "ohtorMC7vFtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#KITTI데이터셋의 세그멘테이션 데이터 다운로드 (Ivan Kreso가 도로영역 라벨링함)\n",
        "#https://www.cvlibs.net/datasets/kitti/eval_semantics.php\n",
        "#https://www.zemris.fer.hr/~ssegvic/multiclod/kitti_semseg_unizg.shtml #Ivan Kreso #KITTI-SEMSEG-UNIZG\n",
        "# road 128 64 128\n",
        "\n",
        "DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/aiffel/CV/semantic_segmentation/data' # 경로 설정\n"
      ],
      "metadata": {
        "id": "d4s_hhXxLOvi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###데이터 로더(data loader) 만들기<br>\n"
      ],
      "metadata": {
        "id": "SOyJHa9JUC3z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXicC4RcS-WR",
        "outputId": "3921900e-36bd-492c-c260-6ed2e2ecc9a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "albumentations                   1.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip list | grep albumentations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#필요한 라이브러리를 로드합니다.\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from glob import glob\n",
        "\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "\n",
        "print('슝=3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-IpChAgVx18",
        "outputId": "b2ec4366-b5f3-4371-9b04-4f397bcdc821"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from albumentations import  HorizontalFlip, RandomSizedCrop, Compose, OneOf, Resize\n",
        "\n",
        "def build_augmentation(is_train=True):\n",
        "  if is_train:    # 훈련용 데이터일 경우\n",
        "    return Compose([\n",
        "                    HorizontalFlip(p=0.5),    # 50%의 확률로 좌우대칭\n",
        "                    RandomSizedCrop(         # 50%의 확률로 RandomSizedCrop\n",
        "                        min_max_height=(300, 370),\n",
        "                        w2h_ratio=370/1242,\n",
        "                        height=224,\n",
        "                        width=224,\n",
        "                        p=0.5\n",
        "                        ),\n",
        "                    Resize(              # 입력이미지를 224X224로 resize\n",
        "                        width=224,\n",
        "                        height=224\n",
        "                        )\n",
        "                    ])\n",
        "  return Compose([      # 테스트용 데이터일 경우에는 224X224로 resize만 수행합니다.\n",
        "                Resize(\n",
        "                    width=224,\n",
        "                    height=224\n",
        "                    )\n",
        "                ])"
      ],
      "metadata": {
        "id": "__aa5wedV2hF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path = '/content/drive/MyDrive/Colab Notebooks/aiffel/CV/semantic_segmentation/data/' # 경로 설정\n",
        "\n",
        "augmentation_train = build_augmentation()\n",
        "augmentation_test = build_augmentation(is_train=False)\n",
        "input_images = glob(os.path.join(dir_path, \"image_2\", \"*.png\"))\n",
        "\n",
        "# 훈련 데이터셋에서 5개만 가져와 augmentation을 적용해 봅시다.\n",
        "plt.figure(figsize=(12, 20))\n",
        "for i in range(len(input_images)):  # 리스트의 실제 크기에 맞춰 루프 범위를 조정\n",
        "    image = imread(input_images[i])\n",
        "    image_data = {\"image\":image}\n",
        "    resized = augmentation_test(**image_data)\n",
        "    processed = augmentation_train(**image_data)\n",
        "    plt.subplot(5, 2, 2*i+1)\n",
        "    plt.imshow(resized[\"image\"])  # 왼쪽이 원본이미지\n",
        "    plt.subplot(5, 2, 2*i+2)\n",
        "    plt.imshow(processed[\"image\"])  # 오른쪽이 augment된 이미지\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Gj5wd5M9V5AA",
        "outputId": "bf15c546-3e45-4016-c9f9-5186cdeee853"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x2000 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class KittiGenerator(tf.keras.utils.Sequence):\n",
        "\n",
        "\n",
        "  def __init__(self, dir_path, batch_size=16, img_size=(224, 224, 3),\n",
        "               output_size=(224, 224), is_train=True, augmentation=None):\n",
        "\n",
        "    self.dir_path = dir_path\n",
        "    self.batch_size = batch_size\n",
        "    self.is_train = is_train\n",
        "    self.augmentation = augmentation\n",
        "    self.img_size = img_size\n",
        "    self.output_size = output_size\n",
        "    self.data = self.load_dataset()  # 데이터셋을 로드합니다.\n",
        "\n",
        "  def load_dataset(self):\n",
        "    '''\n",
        "    데이터셋을 로드하는 함수입니다. 이미지와 라벨의 경로를 로드하고 정렬합니다.\n",
        "    '''\n",
        "    # 입력 이미지와 라벨 이미지의 경로를 가져옵니다.\n",
        "    #/content/drive/MyDrive/Colab Notebooks/aiffel/CV/semantic_segmentation/data/train/rgb\n",
        "    #/content/drive/MyDrive/Colab Notebooks/aiffel/CV/semantic_segmentation/data/train/labels\n",
        "    input_images = glob(os.path.join(self.dir_path, \"train/rgb\", \"*.png\"))\n",
        "    label_images = glob(os.path.join(self.dir_path, \"train/labels\", \"*.png\"))\n",
        "    # 두 리스트를 정렬하여 각 입력 이미지가 해당 라벨과 일치하도록 합니다.\n",
        "    input_images.sort()\n",
        "    label_images.sort()\n",
        "    # 입력과 라벨 이미지의 수가 동일한지 확인합니다.\n",
        "    assert len(input_images) == len(label_images)\n",
        "    # 이미지 경로와 라벨 경로를 튜플로 묶어 리스트에 저장합니다.\n",
        "    data = [ _ for _ in zip(input_images, label_images)]\n",
        "\n",
        "    # 훈련 데이터의 경우 마지막 30개를 제외한 모든 데이터를 사용합니다.\n",
        "    if self.is_train:\n",
        "      return data[:-30]\n",
        "    # 테스트 데이터의 경우 마지막 30개만 사용합니다.\n",
        "    return data[-30:]\n",
        "\n",
        "  def __len__(self):\n",
        "    '''\n",
        "    데이터 생성기의 길이를 반환합니다. 이는 전체 데이터셋을 배치 크기로 나눈 값의 올림과 같습니다.\n",
        "    '''\n",
        "    return math.ceil(len(self.data) / self.batch_size)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    '''\n",
        "    주어진 인덱스에 해당하는 배치를 생성하여 반환합니다.\n",
        "    '''\n",
        "    # 지정된 인덱스에 해당하는 배치의 데이터를 가져옵니다.\n",
        "    batch_data = self.data[index*self.batch_size:(index + 1)*self.batch_size]\n",
        "    # 입력 데이터와 라벨 데이터를 저장할 배열을 준비합니다.\n",
        "    inputs = np.zeros([self.batch_size, *self.img_size[:2], self.img_size[2]])  # (배치 크기, 높이, 너비, 채널)\n",
        "    outputs = np.zeros([self.batch_size, *self.output_size[:2]])  # (배치 크기, 높이, 너비)\n",
        "\n",
        "    # 배치 데이터에 대해 반복하여 입력과 출력 데이터를 처리합니다.\n",
        "    for i, data in enumerate(batch_data):\n",
        "        input_img_path, output_path = data\n",
        "        _input = imread(input_img_path)\n",
        "        _output = imread(output_path)\n",
        "        # augmentation을 적용합니다.\n",
        "        augmented = self.augmentation(image=_input, mask=_output)\n",
        "        # 처리된 이미지와 라벨을 배치 데이터 배열에 저장합니다.\n",
        "        inputs[i] = augmented['image'] / 255  # 이미지 데이터 추출 및 정규화\n",
        "        outputs[i] = augmented['mask'][:,:,0]  # 라벨 데이터의 첫 번째 채널만 추출\n",
        "\n",
        "    return inputs, outputs\n"
      ],
      "metadata": {
        "id": "IEw-ydhEV7cd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmentation = build_augmentation()\n",
        "test_preproc = build_augmentation(is_train=False)\n",
        "\n",
        "train_generator = KittiGenerator(\n",
        "    dir_path,\n",
        "    augmentation=augmentation,\n",
        ")\n",
        "\n",
        "test_generator = KittiGenerator(\n",
        "    dir_path,\n",
        "    augmentation=test_preproc,\n",
        "    is_train=False\n",
        ")"
      ],
      "metadata": {
        "id": "7WwoW8ZFV-J4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. 시맨틱 세그멘테이션 모델"
      ],
      "metadata": {
        "id": "OvAcJBMUrjxK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###모델 구조 만들기<br>\n"
      ],
      "metadata": {
        "id": "7tp28K_MW79S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
        "\n",
        "def build_model(input_shape=(224, 224, 3)):\n",
        "    # 모델 구축 함수를 정의합니다. 기본적인 U-Net 구조를 따릅니다.\n",
        "\n",
        "    # 입력 레이어를 정의합니다. input_shape는 모델이 기대하는 입력 데이터의 형태를 결정합니다.\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # 인코더 시작: 이미지의 특징을 추출하는 컨볼루션 레이어들을 정의합니다.\n",
        "    # Conv2D 레이어는 이미지에 대해 컨볼루션 연산을 수행합니다. 64개의 필터를 사용하고, 커널 크기는 3x3입니다.\n",
        "    # 'relu'는 비선형 활성화 함수입니다. 'padding=same'은 입력과 출력의 크기를 같게 유지합니다.\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    # MaxPooling2D 레이어는 이미지의 크기를 줄이면서 중요한 특징을 유지합니다.\n",
        "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
        "\n",
        "    # 두 번째 컨볼루션 블록. 필터의 수를 두 배로 늘려 더 복잡한 특징을 추출합니다.\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
        "\n",
        "\n",
        "\n",
        "    # 디코더 시작: 인코더를 통해 얻은 특징을 사용하여 이미지의 크기를 원본으로 복원합니다.\n",
        "    # UpSampling2D는 이미지의 크기를 늘립니다. 여기서는 크기를 두 배로 늘립니다.\n",
        "    up1 = UpSampling2D((2, 2))(pool2)\n",
        "    # 컨볼루션 레이어를 사용하여 늘어난 이미지에 다시 특징을 추가합니다.\n",
        "    conv3 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1)\n",
        "    conv3 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv3)\n",
        "\n",
        "    # 이미지의 크기를 다시 두 배로 늘립니다.\n",
        "    up2 = UpSampling2D((2, 2))(conv3)\n",
        "    # 마지막 컨볼루션 레이어를 추가합니다.\n",
        "    conv4 = Conv2D(32, (3, 3), activation='relu', padding='same')(up2)\n",
        "    conv4 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv4)\n",
        "\n",
        "    # 최종 출력 레이어를 추가합니다.\n",
        "    # 1x1 컨볼루션을 사용하여 최종적으로 원하는 채널 수로 특징 맵을 조정합니다.\n",
        "    # 여기서는 1개의 출력 채널을 가지며, 'sigmoid' 활성화 함수를 사용하여 이진 분류 문제에 적합한 출력을 생성합니다.\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(conv4)\n",
        "\n",
        "    # 입력과 출력을 연결하여 최종 모델을 정의합니다.\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n",
        "    # 함수를 호출하면 위에서 정의한 구조의 신경망 모델을 반환합니다.\n"
      ],
      "metadata": {
        "id": "eIlgni5sW_w0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###모델 학습하기<br>\n"
      ],
      "metadata": {
        "id": "MGrkWuEpXHo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/MyDrive/Colab Notebooks/aiffel/CV/semantic_segmentation/seg_model_unet.h5'\n",
        "\n",
        "model = build_model()\n",
        "model.compile(optimizer = Adam(1e-4), loss = 'binary_crossentropy')\n",
        "model.fit(\n",
        "     train_generator,\n",
        "     validation_data=test_generator,\n",
        "     steps_per_epoch=len(train_generator),\n",
        "     epochs=20,\n",
        " )\n",
        "\n",
        "model.save(model_path)  #학습한 모델을 저장해 주세요."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucKFj3DbXKIp",
        "outputId": "b4c3a9f5-efa4-41c9-def1-33a82727a1d0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "24/24 [==============================] - 16s 503ms/step - loss: -74.1777 - val_loss: -359.5092\n",
            "Epoch 2/20\n",
            "24/24 [==============================] - 13s 530ms/step - loss: -1239.2911 - val_loss: -1550.0952\n",
            "Epoch 3/20\n",
            "24/24 [==============================] - 13s 523ms/step - loss: -1581.6356 - val_loss: -1551.1375\n",
            "Epoch 4/20\n",
            "24/24 [==============================] - 13s 528ms/step - loss: -1588.0931 - val_loss: -1551.1683\n",
            "Epoch 5/20\n",
            "24/24 [==============================] - 13s 510ms/step - loss: -1600.2227 - val_loss: -1551.1753\n",
            "Epoch 6/20\n",
            "24/24 [==============================] - 13s 530ms/step - loss: -1585.6791 - val_loss: -1551.1777\n",
            "Epoch 7/20\n",
            "24/24 [==============================] - 14s 549ms/step - loss: -1585.4865 - val_loss: -1551.1799\n",
            "Epoch 8/20\n",
            "24/24 [==============================] - 13s 532ms/step - loss: -1586.9486 - val_loss: -1551.1807\n",
            "Epoch 9/20\n",
            "24/24 [==============================] - 12s 496ms/step - loss: -1590.3872 - val_loss: -1551.1812\n",
            "Epoch 10/20\n",
            "24/24 [==============================] - 13s 524ms/step - loss: -1580.0942 - val_loss: -1551.1814\n",
            "Epoch 11/20\n",
            "24/24 [==============================] - 13s 536ms/step - loss: -1589.1553 - val_loss: -1551.1816\n",
            "Epoch 12/20\n",
            "24/24 [==============================] - 13s 525ms/step - loss: -1587.3550 - val_loss: -1551.1819\n",
            "Epoch 13/20\n",
            "24/24 [==============================] - 13s 530ms/step - loss: -1595.4108 - val_loss: -1551.1821\n",
            "Epoch 14/20\n",
            "24/24 [==============================] - 13s 534ms/step - loss: -1581.6410 - val_loss: -1551.1821\n",
            "Epoch 15/20\n",
            "24/24 [==============================] - 13s 546ms/step - loss: -1591.8608 - val_loss: -1551.1823\n",
            "Epoch 16/20\n",
            "24/24 [==============================] - 13s 528ms/step - loss: -1581.6344 - val_loss: -1551.1824\n",
            "Epoch 17/20\n",
            "24/24 [==============================] - 13s 538ms/step - loss: -1597.7716 - val_loss: -1551.1825\n",
            "Epoch 18/20\n",
            "24/24 [==============================] - 12s 486ms/step - loss: -1590.2920 - val_loss: -1551.1826\n",
            "Epoch 19/20\n",
            "24/24 [==============================] - 13s 525ms/step - loss: -1591.1161 - val_loss: -1551.1826\n",
            "Epoch 20/20\n",
            "24/24 [==============================] - 13s 525ms/step - loss: -1584.5323 - val_loss: -1551.1829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. 시맨틱 세그멘테이션 모델 시각화"
      ],
      "metadata": {
        "id": "9OCOSvblXWwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 미리 준비한 모델을 불러오려면 아래 주석을 해제하세요\n",
        "# model_path = dir_path + '/seg_model_unet.h5'\n",
        "\n",
        "model = tf.keras.models.load_model(model_path)"
      ],
      "metadata": {
        "id": "Ak9NtorFXZMn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_output(model, preproc, image_path, output_path):\n",
        "     origin_img = imread(image_path)\n",
        "     data = {\"image\":origin_img}\n",
        "     processed = preproc(**data)\n",
        "     output = model(np.expand_dims(processed[\"image\"]/255,axis=0))\n",
        "     output = (output[0].numpy()>0.5).astype(np.uint8).squeeze(-1)*255  #0.5라는 threshold를 변경하면 도로인식 결과범위가 달라집니다.\n",
        "     output = Image.fromarray(output)\n",
        "     background = Image.fromarray(origin_img).convert('RGBA')\n",
        "     output = output.resize((origin_img.shape[1], origin_img.shape[0])).convert('RGBA')\n",
        "     output = Image.blend(background, output, alpha=0.5)\n",
        "     output.show()\n",
        "     return output"
      ],
      "metadata": {
        "id": "H9cIHlMjlPQG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image  # 이미지 처리 라이브러리 사용 예시\n",
        "\n",
        "dir_path = '/content/drive/MyDrive/Colab Notebooks/aiffel/CV/semantic_segmentation/data/train/rgb'\n",
        "output_dir = '/content/drive/MyDrive/Colab Notebooks/aiffel/CV/semantic_segmentation/data/train/result'\n",
        "\n",
        "# 디렉토리 내 모든 파일 목록을 얻습니다.\n",
        "file_list = os.listdir(dir_path)\n",
        "\n",
        "# 이미지 파일의 확장자를 지정합니다. 예를 들어 '.png' 또는 '.jpg' 등\n",
        "image_extensions = ['.png', '.jpg', '.jpeg', '.bmp']  # 이미지 확장자 리스트를 수정해주세요.\n",
        "\n",
        "# 이미지 파일만 처리하는 for 루프를 실행합니다.\n",
        "for filename in file_list:\n",
        "    # 파일의 확장자를 소문자로 변환한 뒤 확인합니다.\n",
        "    file_extension = os.path.splitext(filename)[-1].lower()\n",
        "    if file_extension in image_extensions:\n",
        "        # 이미지 파일일 경우에만 작업을 수행합니다.\n",
        "        image_path = os.path.join(dir_path, filename)\n",
        "        output_filename = f'result_{filename}'  # 결과 파일명을 설정합니다.\n",
        "        output_path = os.path.join(output_dir, output_filename)\n",
        "\n",
        "        # 이제 image_path를 이용하여 모델에 입력하고 결과를 output_path에 저장하는 작업을 수행하세요.\n",
        "        # 예를 들어, 이미지를 열고 저장하는 코드는 다음과 같을 수 있습니다.\n",
        "        img = Image.open(image_path)\n",
        "        # 모델에 이미지를 입력하고 결과를 얻는 코드를 추가하세요.\n",
        "\n",
        "        # 결과 이미지를 저장합니다.\n",
        "        img.save(output_path)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tiX--QgQrRyD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dir_path = '/content/drive/MyDrive/Colab Notebooks/aiffel/CV/semantic_segmentation/data/train/result'\n",
        "\n",
        "# 이미지 파일 리스트 생성\n",
        "image_files = [f for f in os.listdir(dir_path) if f.endswith('.png')]\n",
        "\n",
        "for i, image_file in enumerate(image_files):\n",
        "    image_path = os.path.join(dir_path, image_file)\n",
        "    output_path = os.path.join(dir_path, f'result_{str(i).zfill(3)}.png')\n",
        "\n",
        "    get_output(\n",
        "         model,\n",
        "         test_preproc,\n",
        "         image_path=image_path,\n",
        "         output_path=output_path\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "PyPtibO8lW_g"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_iou_score(target, prediction):\n",
        "    # Intersection 계산\n",
        "    intersection = np.logical_and(target, prediction).sum()\n",
        "\n",
        "    # Union 계산\n",
        "    union = np.logical_or(target, prediction).sum()\n",
        "\n",
        "    # IoU 스코어 계산 (0으로 나누는 것을 방지하기 위해 예외 처리)\n",
        "    iou_score = intersection / (union + 1e-5)\n",
        "\n",
        "    print('IoU : %f' % iou_score)\n",
        "\n",
        "    return iou_score\n"
      ],
      "metadata": {
        "id": "BV9W_JrBlaGt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade Pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "g-qOPtqirb5p",
        "outputId": "401fb051-1359-49fa-b4ac-de214751068b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Collecting Pillow\n",
            "  Downloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-10.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pillow 최신 버전 설치 (필요한 경우)\n",
        "!pip install --upgrade Pillow\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def get_output(model, preproc, image_path, output_path, label_path):\n",
        "    # 이미지 읽기 (16비트 이미지를 제대로 처리하기 위해 수정)\n",
        "    origin_img = Image.open(image_path).convert('RGB')  # RGB로 변환\n",
        "    data = {\"image\": np.array(origin_img)}\n",
        "    processed = preproc(**data)\n",
        "    output = model(np.expand_dims(processed[\"image\"] / 255, axis=0))\n",
        "    output = (output[0].numpy() >= 0.5).astype(np.uint8).squeeze(-1) * 255\n",
        "    prediction = output / 255\n",
        "\n",
        "    output_img = Image.fromarray(output)\n",
        "    background = origin_img.convert('RGBA')\n",
        "    output_img = output_img.resize((origin_img.size[0], origin_img.size[1])).convert('RGBA')\n",
        "    output_img = Image.blend(background, output_img, alpha=0.5)\n",
        "    output_img.show()\n",
        "\n",
        "    if label_path:\n",
        "        label_img = Image.open(label_path).convert('L')  # 그레이스케일 변환\n",
        "        label_data = {\"image\": np.array(label_img)}\n",
        "        label_processed = preproc(**label_data)\n",
        "        label_processed = label_processed[\"image\"]\n",
        "        target = (label_processed == 7).astype(np.uint8)\n",
        "\n",
        "        return output_img, prediction, target\n",
        "    else:\n",
        "        return output_img, prediction, None\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYALmT0dlbcO",
        "outputId": "1d5066d1-51e9-413e-c950-76b69020a301"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (10.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path = '/content/drive/MyDrive/Colab Notebooks/aiffel/CV/semantic_segmentation/data/train/'\n",
        "\n",
        "def create_file_path(dir_path, file_type, series, i):\n",
        "    file_number = f\"{series}_{str(i).zfill(6)}\"\n",
        "    if file_type == 'image':\n",
        "        return f'{dir_path}result/result_{file_number}.png'\n",
        "    elif file_type == 'output':\n",
        "        return f'{dir_path}result/result_{file_number}.png'\n",
        "    elif file_type == 'label':\n",
        "        # 'depth' 폴더 대신 'labels' 폴더를 사용\n",
        "        return f'{dir_path}labels/{file_number}.png'\n",
        "\n",
        "# 시리즈 번호와 이미지 번호를 변수로 사용\n",
        "series_number = '00'\n",
        "image_number = 540  # 혹은 원하는 다른 번호로 변경 가능\n",
        "\n",
        "image_path = create_file_path(dir_path, 'image', series_number, image_number)\n",
        "output_path = create_file_path(dir_path, 'output', series_number, image_number)\n",
        "label_path = create_file_path(dir_path, 'label', series_number, image_number)\n",
        "\n",
        "output, prediction, target = get_output(model, test_preproc, image_path, output_path, label_path)\n",
        "iou_score = calculate_iou_score(target, prediction)\n",
        "print(f\"IOU Score: {iou_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24dNQIF5ldDz",
        "outputId": "53de32ba-0cb4-4baa-d975-3b2d7b8c8d4c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IoU : 0.000140\n",
            "IOU Score: 0.00013950892854362463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###회고:"
      ],
      "metadata": {
        "id": "XRi-UkzvryL0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "epochs=20으로 설정한 결과<br>IoU : 0.000140,\n",
        "IOU Score: 0.00013950892854362463이 나왔다.<br>이것은 매우 낮은 성능을 의미하고 있다.<br>애초에 100으로 epoch을 설정한 이유가 있는 것 같다. 이러한 결과는 모델이 타겟 객체를 거의 탐지하지 못했거나, 완전히 잘못 탐지했다는 것을 의미한다. <br>낮은 결과값의 전반적인 원인들은<br>1.데이터 처리의 문제: 입력 데이터가 적절히 처리되지 않았거나, 라벨링에 오류가 있을 수 있다.<br>2.\n",
        "모델 구조의 부적절함: 사용된 모델이 특정 데이터셋에 적합하지 않거나, 충분히 학습되지 않았을 가능성이 있다.<br>3.\n",
        "하이퍼파라미터 설정의 문제: 학습률, 배치 크기, 에포크 수 등의 하이퍼파라미터 설정이 최적화되지 않았을 수 있다.<br>4.\n",
        "과소적합 문제: 모델이 너무 단순하여 데이터의 복잡성을 충분히 학습하지 못했을 수 있다. 라고 생각해볼 수 있을 것 같다."
      ],
      "metadata": {
        "id": "KMXG7AUlsJTk"
      }
    }
  ]
}